{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según las webadas que leo, el csp responde a esta simple ecuación:\n",
    "\n",
    "$$S = WA$$\n",
    "\n",
    "Donde W es el resultado del algoritmo CSP (que al parecer proviene de la rama de procesamiento de señales). $A$ es la matriz de entrada (que al parecer tiene más dimensiones de las que pensaba - channels $\\times$ samples), y S es la matriz de salida (que debería ser sources $\\times$ samples).\n",
    "\n",
    "Por eso voy a analizar linea por línea el código de la [función fit de mne](https://github.com/mne-tools/mne-python/blob/maint/0.19/mne/decoding/csp.py#L144-L255)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo variables\n",
    "\n",
    "$X$ e $y$ son los inputs. $X$ es la matriz de epochs, donde cada epoch es una matriz de channels $\\times$ samples (epochs $\\times$ channels $\\times$ samples). $y$, por otro lado, es un arreglo con las clases de cada epoch.\n",
    "\n",
    "Otros datos que se necesitan son:\n",
    "* Número de canales (que se obtiene de $X$)\n",
    "* Número de classes (que se obtiene de $y$)\n",
    "* Una matriz de covarianza (que es classes $\\times$ channels $\\times$ channels y no sé por qué)\n",
    "* Una lista con los pesos de las muestras o sample (supongo que cada epoch debe tener un número igual de samples para que funcione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self._classes = np.unique(y)\n",
    "\n",
    "n_channels = X.shape[1]\n",
    "n_classes = len(self._classes)\n",
    "\n",
    "covs = np.zeros((n_classes, n_channels, n_channels))\n",
    "sample_weights = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando la matriz de covarianza por clase\n",
    "\n",
    "Supongo que la matriz de convarianza es de channels $\\times$ channels, o 14 $\\times$ 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_idx, this_class in enumerate(self._classes):\n",
    "    class_ = np.transpose(X[y == this_class], [1, 0, 2])\n",
    "    class_ = class_.reshape(n_channels, -1)\n",
    "    cov = _regularized_covariance(class_, reg=self.reg, method_params=self.cov_method_params, rank=self.rank)\n",
    "    weight = sum(y == this_class)\n",
    "\n",
    "    covs[class_idx] = cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a detenernos en esta línea. Se seleccionan solo los epochs pertenecientes a esa clase con `X[y == this_class]`. Y luego se transpone de tal forma que, antes:\n",
    "\n",
    "* Teníamos los epochs, y dentro de cada epoch teníamos todos los canales\n",
    "\n",
    "Y ahora:\n",
    "\n",
    "* Tenemos todos los canales, y dentro de cada uno los epochs\n",
    "\n",
    "Si la finalidad es convertir una matriz de channels $\\times$ samples a una de sources $\\times$ samples, yo diría que es el camino correcto... creo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ = np.transpose(X[y == this_class], [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[3., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[4., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[5., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# epochs × channels × samples\n",
    "epochs = 5 # 5 epochs of 1 seg each\n",
    "channels = 5 # Insight\n",
    "samples = 10 # 10Hz\n",
    "X = np.zeros((epochs, channels, samples))\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X[i][0][0] = i + 1\n",
    "    \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.random.randint(0, 2, size=epochs)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[3., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[y == 1] # epochs x channels x samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [3., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ = np.transpose(X[y == 1], [1, 0, 2]) # channels x epochs x samples\n",
    "class_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí estoy concatenando los epochs por channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ = class_.reshape(channels, -1)\n",
    "class_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí llegué, necesito revisar las cosas de algebra lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_regularized_covariance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-77b4924e30ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_regularized_covariance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov_method_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '_regularized_covariance' is not defined"
     ]
    }
   ],
   "source": [
    "cov = _regularized_covariance(class_, reg=self.reg, method_params=self.cov_method_params, rank=self.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _regularized_covariance(data, reg=None, method_params=None, info=None,\n",
    "                            rank=None):\n",
    "    \"\"\"Compute a regularized covariance from data using sklearn.\n",
    "    This is a convenience wrapper for mne.decoding functions, which\n",
    "    adopted a slightly different covariance API.\n",
    "    Returns\n",
    "    -------\n",
    "    cov : ndarray, shape (n_channels, n_channels)\n",
    "        The covariance matrix.\n",
    "    \"\"\"\n",
    "    if reg is None:\n",
    "        reg = 'empirical'\n",
    "    try:\n",
    "        reg = float(reg)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if isinstance(reg, float):\n",
    "        if method_params is not None:\n",
    "            raise ValueError('If reg is a float, method_params must be None '\n",
    "                             '(got %s)' % (type(method_params),))\n",
    "        method_params = dict(shrinkage=dict(\n",
    "            shrinkage=reg, assume_centered=True, store_precision=False))\n",
    "        reg = 'shrinkage'\n",
    "    elif not isinstance(reg, str):\n",
    "        raise ValueError('reg must be a float, str, or None, got %s (%s)'\n",
    "                         % (reg, type(reg)))\n",
    "    method, method_params = _check_method_params(\n",
    "        reg, method_params, name='reg', allow_auto=False, rank=rank)\n",
    "    # use mag instead of eeg here to avoid the cov EEG projection warning\n",
    "    info = create_info(data.shape[-2], 1000., 'mag') if info is None else info\n",
    "    picks_list = _picks_by_type(info)\n",
    "    scalings = _handle_default('scalings_cov_rank', None)\n",
    "    cov = _compute_covariance_auto(\n",
    "        data.T, method=method, method_params=method_params,\n",
    "        info=info, cv=None, n_jobs=1, stop_early=True,\n",
    "        picks_list=picks_list, scalings=scalings,\n",
    "        rank=rank)[reg]['data']\n",
    "    return cov"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
