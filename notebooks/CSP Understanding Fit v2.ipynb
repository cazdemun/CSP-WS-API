{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nota: Esta versión ya tiene un entendimiento más profundo de los pasos requeridos del algoritmo, pero falta entender la teoría de los autovectores\n",
    "\n",
    "> Nota: Versión 3 implenta el código hasta covarianza. Versión 4 incluye el entendimiento de los autovectores. v5 el código correspondiente. v6 debería incluir transform y todos felices.\n",
    "\n",
    "Según [Kothe (2011)](https://www.youtube.com/playlist?list=PLbbCsk7MUIGcO_lZMbyymWU2UezVHNaMq), el algoritmo Common Spatial Pattern (CSP) resuelve el siguiente problema, llamado también [spatial filter problem](https://www.youtube.com/watch?v=S4znknOIcRk):\n",
    "\n",
    "$$S = WA$$\n",
    "\n",
    "Donde W es el resultado del algoritmo CSP (que al parecer proviene de la rama de procesamiento de señales). $A$ es la matriz de entrada (que al parecer tiene más dimensiones de las que pensaba - channels $\\times$ samples), y S es la matriz de salida (que debería ser sources $\\times$ samples).\n",
    "\n",
    "Fatal: usa imágenes\n",
    "\n",
    "El problema de filtros espaciales puede resumirse de la siguiente forma: Teniendo una fuente de información ($A$), ya sea a través de sensores, micrófonos, electrodos, etc; se quiere hallar las fuentes de esas señales ($S$). Debido a razones biológicas, los sensores no captan los lugares precisos de donde se generan estas señales. Así, un electrodo ubicado en la parte derecha de la cabeza puede captar con más fuerza una señal generada dentro del hemisferio izquierdo del cerebro que un electrodo de ubicado justo por encima de esa zona, dependiendo de diversos factores.\n",
    "\n",
    "Por eso voy a analizar linea por línea el código de la [función fit de mne](https://github.com/mne-tools/mne-python/blob/maint/0.19/mne/decoding/csp.py#L144-L255)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementción MNE de Common Spatial Pattern\n",
    "\n",
    "Los parámetros del algoritmo/objeto CSP, según la [documentación](https://github.com/mne-tools/mne-python/blob/maint/0.19/mne/decoding/csp.py#L144-L255), son:\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_components : int, default 4\n",
    "            The number of components to decompose M/EEG signals.\n",
    "            This number should be set by cross-validation.\n",
    "        reg : float | str | None (default None)\n",
    "            If not None (same as ``'empirical'``, default), allow\n",
    "            regularization for covariance estimation.\n",
    "            If float, shrinkage is used (0 <= shrinkage <= 1).\n",
    "            For str options, ``reg`` will be passed to ``method`` to\n",
    "            :func:`mne.compute_covariance`.\n",
    "        log : None | bool (default None)\n",
    "            If transform_into == 'average_power' and log is None or True, then\n",
    "            applies a log transform to standardize the features, else the features\n",
    "            are z-scored. If transform_into == 'csp_space', then log must be None.\n",
    "        cov_est : 'concat' | 'epoch', default 'concat'\n",
    "            If 'concat', covariance matrices are estimated on concatenated epochs\n",
    "            for each class.\n",
    "            If 'epoch', covariance matrices are estimated on each epoch separately\n",
    "            and then averaged over each class.\n",
    "        transform_into : {'average_power', 'csp_space'}\n",
    "            If 'average_power' then self.transform will return the average power of\n",
    "            each spatial filter. If 'csp_space' self.transform will return the data\n",
    "            in CSP space. Defaults to 'average_power'.\n",
    "        norm_trace : bool\n",
    "            Normalize class covariance by its trace. Defaults to False. Trace\n",
    "            normalization is a step of the original CSP algorithm [1]_ to eliminate\n",
    "            magnitude variations in the EEG between individuals. It is not applied\n",
    "            in more recent work [2]_, [3]_ and can have a negative impact on\n",
    "            patterns ordering.\n",
    "        cov_method_params : dict | None\n",
    "            Parameters to pass to :func:`mne.compute_covariance`.\n",
    "            \n",
    "Y la inicialización en el [tutorial](https://mne.tools/stable/auto_examples/decoding/plot_decoding_csp_eeg.html) es:\n",
    "\n",
    "        csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "\n",
    "Lo cual nos deja con ciertas suposiciones:\n",
    "\n",
    "* Solo se clasificarán dos variables por ahora\n",
    "* `cov_est` será concat\n",
    "* `norm_trace` es falso\n",
    "\n",
    "Eliminaremos también ciertas validaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fit(self, X, y):\n",
    "        \"\"\"Estimate the CSP decomposition on epochs.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_epochs, n_channels, n_times)\n",
    "            The data on which to estimate the CSP.\n",
    "        y : array, shape (n_epochs,)\n",
    "            The class for each epoch.\n",
    "        Returns\n",
    "        -------\n",
    "        self : instance of CSP\n",
    "            Returns the modified instance.\n",
    "        \"\"\"\n",
    "        n_channels = X.shape[1]\n",
    "\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        covs = np.zeros((n_classes, n_channels, n_channels))\n",
    "        # sample_weights = list() # multiclass\n",
    "        \n",
    "        for class_idx, this_class in enumerate(self._classes):\n",
    "            \n",
    "            if self.cov_est == \"concat\":  # concatenate epochs\n",
    "                class_ = np.transpose(X[y == this_class], [1, 0, 2])\n",
    "                class_ = class_.reshape(n_channels, -1)\n",
    "                cov = _regularized_covariance(\n",
    "                    class_, reg=self.reg, method_params=self.cov_method_params,\n",
    "                    rank=self.rank)\n",
    "                weight = sum(y == this_class)\n",
    "\n",
    "            covs[class_idx] = cov\n",
    "            # sample_weights.append(weight) # multiclass\n",
    "\n",
    "        if n_classes == 2:\n",
    "            eigen_values, eigen_vectors = linalg.eigh(covs[0], covs.sum(0))\n",
    "            # sort eigenvectors\n",
    "            ix = np.argsort(np.abs(eigen_values - 0.5))[::-1]\n",
    "\n",
    "        # sort eigenvectors\n",
    "        eigen_vectors = eigen_vectors[:, ix]\n",
    "\n",
    "        self.filters_ = eigen_vectors.T\n",
    "        self.patterns_ = linalg.pinv2(eigen_vectors)\n",
    "\n",
    "        pick_filters = self.filters_[:self.n_components]\n",
    "        X = np.asarray([np.dot(pick_filters, epoch) for epoch in X])\n",
    "\n",
    "        # compute features (mean band power)\n",
    "        X = (X ** 2).mean(axis=2)\n",
    "\n",
    "        # To standardize features\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        self.std_ = X.std(axis=0)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "El objetivo principal es conseguir los patrones y los filtros a partir de $X$, $y$. O sea estas líneas de acá:\n",
    "\n",
    "        self.filters_ = eigen_vectors.T\n",
    "        self.patterns_ = linalg.pinv2(eigen_vectors)\n",
    "\n",
    "Eso quiere decir que tenemos que hallar los autovectores de algo... que es la matriz de covarianza.\n",
    "\n",
    "        cov = _regularized_covariance(\n",
    "                    class_, reg=self.reg, method_params=self.cov_method_params,\n",
    "                    rank=self.rank) \n",
    "                    \n",
    "Y esta matriz la sacamos de... $X$, solo que hay que modificarlo un poquito. Pero en todo caso el pipeline simplificado es el siguiente:\n",
    "\n",
    "1. Transformar $X$ a $X'$\n",
    "2. Hallar la matriz de covarianza de $X'$\n",
    "3. Hallar los autovectores a partir de $C_X$\n",
    "\n",
    "$y$ es importante porque no vamos a hallar solo una matriz de covarianza, sino varias (el número de clases únicas en $y$). Esto último creo que solo es necesario para las clasificación multiclass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transformar $X$ a $X'$\n",
    "\n",
    "Para entender esta parte del código es importante entender la representación de la data. Tres transformaciones principales sufren los datos desde que se obtienen hasta que son usados por el algoritmo CSP.\n",
    "\n",
    "Primero, la data es guardada en una matriz canales $\\times$ tiempo. En esta matriz están concatenadas todas las sesiones de todos los movimientos, pero nosotros hemos anotado los tiempos y clases de antemano. El siguiente sería un ejemplo de las ondas cerebrales concatenadas y con anotaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagen del otro cuaderno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar en general con esta información, primero se separa la información en epochs. Los epochs son ventanas de tiempo que también son matrices canales $\\times$ tiempo. La diferencia es que tienen guardado el tiempo exacto en el cual se ejecutó el movimiento. Todos estos epochs se guardan en un gran arreglo, y ahí viene la primera gran transformación:\n",
    "\n",
    "$$ channels \\times samples \\rightarrow epochs \\times channels \\times samples $$\n",
    "\n",
    "Samples viene a ser lo mismo que el tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo variables\n",
    "\n",
    "$X$ e $y$ son los inputs. $X$ es la matriz de epochs, donde cada epoch es una matriz de channels $\\times$ samples (epochs $\\times$ channels $\\times$ samples). $y$, por otro lado, es un arreglo con las clases de cada epoch.\n",
    "\n",
    "Otros datos que se necesitan son:\n",
    "* Número de canales (que se obtiene de $X$)\n",
    "* Número de clases (que se obtiene de $y$)\n",
    "* Una matriz de covarianza (que es classes $\\times$ channels $\\times$ channels y no sé por qué)\n",
    "* Una lista con los pesos de las muestras o sample (supongo que cada epoch debe tener un número igual de samples para que funcione)\n",
    "\n",
    "Otros datos que se necesitan son (v2):\n",
    "* Número de canales (que se obtiene de $X$)\n",
    "* Número de clases (que se obtiene de $y$)\n",
    "* Una matriz de covarianza (que es classes $\\times$ channels $\\times$ channels)\n",
    "* Una lista con los pesos de las muestras o sample (pesos por clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self._classes = np.unique(y)\n",
    "\n",
    "n_channels = X.shape[1]\n",
    "n_classes = len(self._classes)\n",
    "\n",
    "covs = np.zeros((n_classes, n_channels, n_channels))\n",
    "sample_weights = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando la matriz de covarianza por clase\n",
    "\n",
    "Supongo que la matriz de convarianza es de channels $\\times$ channels, o 14 $\\times$ 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_idx, this_class in enumerate(self._classes):\n",
    "    class_ = np.transpose(X[y == this_class], [1, 0, 2])\n",
    "    class_ = class_.reshape(n_channels, -1)\n",
    "    cov = _regularized_covariance(class_, reg=self.reg, method_params=self.cov_method_params, rank=self.rank)\n",
    "    weight = sum(y == this_class)\n",
    "\n",
    "    covs[class_idx] = cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a detenernos en esta línea. Se seleccionan solo los epochs pertenecientes a esa clase con `X[y == this_class]`. Y luego se transpone de tal forma que, antes:\n",
    "\n",
    "* Teníamos los epochs, y dentro de cada epoch teníamos todos los canales\n",
    "\n",
    "Y ahora:\n",
    "\n",
    "* Tenemos todos los canales, y dentro de cada uno los epochs\n",
    "\n",
    "Si la finalidad es convertir una matriz de channels $\\times$ samples a una de sources $\\times$ samples, yo diría que es el camino correcto... creo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ = np.transpose(X[y == this_class], [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[3., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[4., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[5., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# epochs × channels × samples\n",
    "epochs = 5 # 5 epochs of 1 seg each\n",
    "channels = 5 # Insight\n",
    "samples = 10 # 10Hz\n",
    "X = np.zeros((epochs, channels, samples))\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X[i][0][0] = i + 1\n",
    "    \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.random.randint(0, 2, size=epochs)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = sum(y == 1)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = sum(y == 0)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False,  True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[4., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[y == 1] # epochs x channels x samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [4., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ = np.transpose(X[y == 1], [1, 0, 2]) # channels x epochs x samples\n",
    "class_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí estoy concatenando los epochs por channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ = class_.reshape(channels, -1)\n",
    "class_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí llegué, necesito revisar las cosas de algebra lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_regularized_covariance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-77b4924e30ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_regularized_covariance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov_method_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name '_regularized_covariance' is not defined"
     ]
    }
   ],
   "source": [
    "cov = _regularized_covariance(class_, reg=self.reg, method_params=self.cov_method_params, rank=self.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _regularized_covariance(data, reg=None, method_params=None, info=None,\n",
    "                            rank=None):\n",
    "    \"\"\"Compute a regularized covariance from data using sklearn.\n",
    "    This is a convenience wrapper for mne.decoding functions, which\n",
    "    adopted a slightly different covariance API.\n",
    "    Returns\n",
    "    -------\n",
    "    cov : ndarray, shape (n_channels, n_channels)\n",
    "        The covariance matrix.\n",
    "    \"\"\"\n",
    "    if reg is None:\n",
    "        reg = 'empirical'\n",
    "    try:\n",
    "        reg = float(reg)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if isinstance(reg, float):\n",
    "        if method_params is not None:\n",
    "            raise ValueError('If reg is a float, method_params must be None '\n",
    "                             '(got %s)' % (type(method_params),))\n",
    "        method_params = dict(shrinkage=dict(\n",
    "            shrinkage=reg, assume_centered=True, store_precision=False))\n",
    "        reg = 'shrinkage'\n",
    "    elif not isinstance(reg, str):\n",
    "        raise ValueError('reg must be a float, str, or None, got %s (%s)'\n",
    "                         % (reg, type(reg)))\n",
    "    method, method_params = _check_method_params(\n",
    "        reg, method_params, name='reg', allow_auto=False, rank=rank)\n",
    "    # use mag instead of eeg here to avoid the cov EEG projection warning\n",
    "    info = create_info(data.shape[-2], 1000., 'mag') if info is None else info\n",
    "    picks_list = _picks_by_type(info)\n",
    "    scalings = _handle_default('scalings_cov_rank', None)\n",
    "    cov = _compute_covariance_auto(\n",
    "        data.T, method=method, method_params=method_params,\n",
    "        info=info, cv=None, n_jobs=1, stop_early=True,\n",
    "        picks_list=picks_list, scalings=scalings,\n",
    "        rank=rank)[reg]['data']\n",
    "    return cov"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
